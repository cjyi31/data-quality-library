{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0378017e-55a2-4c91-9c50-398d7c0a856a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####1.Load Business Rules Conf file (NO NEED TO UPDATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0646bb56-c9a6-4465-b4c2-82fc237c8ee2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load business rules conf\n"
     ]
    }
   ],
   "source": [
    "jsonFileString = r'''\n",
    "{\n",
    "    \"fields\": [\n",
    "        \"Policy_ID\",\n",
    "        \"Holder_Age\",\n",
    "        \"Email_Address\",\n",
    "        \"Policy_Start_Date\"\n",
    "    ],\n",
    "    \"rules\": {\n",
    "        \"Policy_ID\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^POL\\\\d{4}$\"\n",
    "            }\n",
    "        },\n",
    "        \"Holder_Age\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"min\": 18,\n",
    "                \"max\": 99\n",
    "            }\n",
    "        },\n",
    "        \"Email_Address\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$\"\n",
    "            },\n",
    "            \"accuracy\": null\n",
    "        },\n",
    "        \"Policy_Start_Date\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"date_format\": \"%Y-%m-%d\"\n",
    "            },\n",
    "            \"accuracy\": null\n",
    "        },\n",
    "        \"Phone_Number_JP\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^[0-9]{1,4}-[0-9]{1,4}-[0-9]{4}$\"\n",
    "            }\n",
    "        },\n",
    "        \"Phone_Number_IN\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^[6-9]\\\\d{9}$\"\n",
    "            }\n",
    "        },\n",
    "        \"Phone_Number_CN\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^1[3-9]\\\\d{9}$\"\n",
    "            }\n",
    "        },\n",
    "        \"Phone_Number_ID\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^\\\\+62[ -]?[2-9]\\\\d{2}[ -]?\\\\d{3,8}$\"\n",
    "            }\n",
    "        },\n",
    "        \"Phone_Number_MY\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^\\\\+60[ -]?[1-9]\\\\d{1,2}[ -]?\\\\d{6,7}$\"\n",
    "            }\n",
    "        },\n",
    "        \"Zip_Code_JP\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^\\\\d{3}-\\\\d{4}$\"\n",
    "            }\n",
    "        },\n",
    "        \"Zip_Code_AU\": {\n",
    "            \"completeness\": true,\n",
    "            \"validity\": {\n",
    "                \"regex\": \"^\\\\d{4}$\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Assuming load_business_rules() parses a JSON string:\n",
    "import json\n",
    "\n",
    "\n",
    "def load_business_rules(json_string):\n",
    "    return json.loads(json_string)\n",
    "\n",
    "config_json = load_business_rules(jsonFileString)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"load business rules conf\")\n",
    "def load_business_rules(file_path):\n",
    "    # Open the file and load the JSON content into a dictionary\n",
    "    with open(file_path, 'r') as file:\n",
    "        rules = json.load(file)\n",
    "    return rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6120db4-eb00-47c4-a6b0-261304f5e6ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####2.Load DQ functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc864e10-c6db-4035-995d-5f97d6c859ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "# Step 2: Create a Sample Configuration JSON Object\n",
    "# This is a simplified version of the rules that would be in the config file.\n",
    "\n",
    "\n",
    "def load_business_rules(file_path):\n",
    "    # Open the file and load the JSON content into a dictionary\n",
    "    with open(file_path, 'r') as file:\n",
    "        rules = json.load(file)\n",
    "    return rules\n",
    "\n",
    "\n",
    "business_rules_path = '/Workspace/20231103.ADA.DQ/data-quality-rules-library.json'\n",
    "config_json = load_business_rules(business_rules_path)\n",
    "\n",
    "\n",
    "# Define the functions for DQ checks\n",
    "\n",
    "def check_completeness(value):\n",
    "    # Check if the value is a string and if it's empty or represents a missing value\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip().lower()  # Trim whitespace and convert to lowercase\n",
    "        if value in [\"\", \"null\", \"nil\", \"n/a\", \"na\", \"-\", \"--\"]:\n",
    "            return False\n",
    "    return not pd.isnull(value)\n",
    "\n",
    "\n",
    "def check_validity(field, value, rules):\n",
    "    if pd.isnull(value) or value in [\"\", \"null\", \"nan\", \"N/A\", \"n/a\"]:\n",
    "        return False  # Incomplete data is also invalid\n",
    "    if \"type\" in rules:\n",
    "        if rules[\"type\"] == \"integer\":\n",
    "            try:\n",
    "                int_value = int(value)  # Attempt to convert to integer\n",
    "            except ValueError:\n",
    "                return False  # Non-integer value\n",
    "            if \"min\" in rules and int_value < rules[\"min\"]:\n",
    "                return False\n",
    "            if \"max\" in rules and int_value > rules[\"max\"]:\n",
    "                return False\n",
    "    if \"regex\" in rules:\n",
    "        if not re.match(rules[\"regex\"], str(value)):\n",
    "            return False\n",
    "    if \"date_format\" in rules:\n",
    "        try:\n",
    "            datetime.strptime(str(value), rules[\"date_format\"])\n",
    "        except ValueError:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def check_accuracy(field, value, rules):\n",
    "    # Placeholder for a custom function based on rules\n",
    "    # Assuming a function for accuracy check is defined elsewhere and can be called here.\n",
    "    # For now, we just return True, as we don't have any specific logic to check accuracy.\n",
    "    return True\n",
    "\n",
    "# Update the calculation of the Data Quality metrics to use the correct formula\n",
    "\n",
    "def calculate_data_quality_metrics(df, dq_flags):\n",
    "    # Calculate DQ metrics for each field\n",
    "    dq_metrics = {}\n",
    "    for field, (comp, valid, acc) in dq_flags.items():\n",
    "        completeness = df[comp].mean()\n",
    "        validity = df[df[comp]][valid].mean()  # % Valid among complete\n",
    "        accuracy = df[df[valid]][acc].mean()  # % Accurate among valid\n",
    "        data_quality = completeness * validity * accuracy\n",
    "        dq_metrics[field] = {\n",
    "            \"Completeness\": completeness,\n",
    "            \"Validity\": validity,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Data Quality\": data_quality\n",
    "        }\n",
    "\n",
    "    # Calculate overall DQ metrics\n",
    "    overall_completeness = df[[comp for comp, _, _ in dq_flags.values()]].mean().mean()\n",
    "    overall_validity = df[[valid for _, valid, _ in dq_flags.values()]].mean().mean()\n",
    "    overall_accuracy = df[[acc for _, _, acc in dq_flags.values()]].mean().mean()\n",
    "    overall_dq = overall_completeness * overall_validity * overall_accuracy\n",
    "\n",
    "    dq_metrics[\"Overall\"] = {\n",
    "        \"Completeness\": overall_completeness,\n",
    "        \"Validity\": overall_validity,\n",
    "        \"Accuracy\": overall_accuracy,\n",
    "        \"Data Quality\": overall_dq\n",
    "    }\n",
    "\n",
    "    return dq_metrics\n",
    "\n",
    "# Update the main function to include the correct DQ metric calculation\n",
    "def calculate_data_quality(df, config):\n",
    "    dq_flags = {}\n",
    "\n",
    "    for field in config['fields']:\n",
    "        completeness_col = f\"{field}__Completeness\"\n",
    "        validity_col = f\"{field}__Validity\"\n",
    "        accuracy_col = f\"{field}__Accuracy\"\n",
    "\n",
    "        df[completeness_col] = df[field].apply(check_completeness)\n",
    "        df[validity_col] = df.apply(lambda row: check_validity(field, row[field], config['rules'].get(field, {}).get('validity', {})), axis=1)\n",
    "        df[accuracy_col] = df.apply(lambda row: check_accuracy(field, row[field], config['rules'].get(field, {}).get('accuracy', {})), axis=1)\n",
    "\n",
    "        dq_flags[field] = (completeness_col, validity_col, accuracy_col)\n",
    "\n",
    "    dq_metrics = calculate_data_quality_metrics(df, dq_flags)\n",
    "\n",
    "    # Create a summary dataframe for the DQ metrics\n",
    "    dq_summary = pd.DataFrame.from_dict(dq_metrics, orient='index')\n",
    "\n",
    "    return df, dq_summary\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "_dq-library",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
